{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of policy iteration (Sutton and Barto, section 4.3, page 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    '''\n",
    "    Initializes the agent\n",
    "    @param rows - The number of rows in the grid world\n",
    "    @param columns - The number of columns in the grid world\n",
    "    @param terminal_state - The final state the agent is trying to find the best path to\n",
    "    '''\n",
    "    def __init__(self, rows, columns, terminal_state, theta=0.05, gamma=0.05):\n",
    "        # self.grid = np.random.rand(rows, columns) * -1 # Initializes\n",
    "        self.rows = rows\n",
    "        self.columns = columns\n",
    "        self.values = np.zeros((rows, columns)) # Initializes all state values to zero\n",
    "        self.policies = self.initializePolicies()\n",
    "        # self.policies = self.initializePolicies() # Initializes policies for each cell,\n",
    "        #                                           # policies[row][column] is an array where the value\n",
    "        #                                           # at index 0 is the probability that up is the optimal choice,\n",
    "        #                                           # 1 is right, 2 is down, 3 is left (clockwise around Cartesian)\n",
    "        self.terminal_state = terminal_state # Where the end state is located on the grid\n",
    "        self.theta = theta # A value close to zero signifying completion, determines the accuracy of the policy estimation\n",
    "        self.gamma = gamma # A value signifying by how much to discount future rewards \n",
    "\n",
    "    '''\n",
    "    Initializes the policies for each cell in the grid world\n",
    "    '''\n",
    "    def initializePolicies(self):\n",
    "        policies = np.empty((self.rows, self.columns, 4))\n",
    "\n",
    "        # Fill the array with random values that sum to 1\n",
    "        for i in range(self.rows):\n",
    "            for j in range(self.columns):\n",
    "                policies[i, j] = np.random.dirichlet(np.ones(4))\n",
    "                # policies[i, j] = np.zeros(4)\n",
    "                # policies[i, j][np.random.randint(4)] = 1\n",
    "\n",
    "        return policies\n",
    "\n",
    "    def isValidState(self, coords):\n",
    "        return coords[0] >= 0 and coords[0] < self.rows and coords[1] >= 0 and coords[1] < self.columns\n",
    "\n",
    "    '''\n",
    "    Gets the available successor states (necessary because our grid world has walls)\n",
    "    @param coords - coordinates in tuple form (x, y) of our state\n",
    "    @return a list of successors\n",
    "    '''\n",
    "    def getAvailableSuccessorStates(self, coords):\n",
    "        successors = []\n",
    "        \n",
    "        # if coords[1] != 0:\n",
    "        successors.append((coords[0] - 1, coords[1]))\n",
    "\n",
    "        # if coords[0] != self.rows - 1:\n",
    "        successors.append((coords[0], coords[1] + 1))\n",
    "\n",
    "        # if coords[1] != self.columns - 1:\n",
    "        successors.append((coords[0] + 1, coords[1]))\n",
    "\n",
    "        # if coords[0] != 0:\n",
    "        successors.append((coords[0], coords[1] - 1))\n",
    "\n",
    "        return successors\n",
    "\n",
    "    def getDiscountedValuesForSuccessors(self, state):\n",
    "        values = np.zeros(4)\n",
    "        \n",
    "        successors = self.getAvailableSuccessorStates(state[0]) # Get possible next states\n",
    "        \n",
    "        value = 0\n",
    "        for successor in range(len(successors)):\n",
    "            if self.isValidState(successors[successor]):\n",
    "                probability_successor_chosen = self.policies[state[0][0]][state[0][1]][successor]\n",
    "                successor_value = self.getReward(successors[successor]) + self.gamma * self.values[successors[successor][0]][successors[successor][1]]\n",
    "                values[successor] = probability_successor_chosen * successor_value\n",
    "        \n",
    "        # print(state, successors, values)\n",
    "\n",
    "        return values\n",
    "\n",
    "    def updatePolicy(self, coords):\n",
    "        successors = self.getAvailableSuccessorStates(coords)\n",
    "        values = np.ones(4) / 4\n",
    "        for successor in range(len(successors)):\n",
    "            if self.isValidState(successors[successor]):\n",
    "                values[successor] = self.values[successors[successor][0]][successors[successor][1]] + self.getReward(successors[successor])\n",
    "            else:\n",
    "                values[successor] = 0\n",
    "                # print(\"Invalid\", coords, successors[successor])\n",
    "        \n",
    "        sum = np.sum(values)\n",
    "        policies = np.ones(4) / 4 if sum == 0 else values / sum\n",
    "\n",
    "        self.policies[coords[0]][coords[1]] = policies\n",
    "\n",
    "\n",
    "    def getReward(self, state):\n",
    "        if state[0] == self.terminal_state[0] and state[1] == self.terminal_state[1]:\n",
    "            # print(state, self.terminal_state)\n",
    "            return 100\n",
    "        return 0\n",
    "        \n",
    "\n",
    "    '''\n",
    "    Performs a policy evaluation step, updates the policy\n",
    "    '''\n",
    "    def policyEvaluation(self):\n",
    "        while True:\n",
    "            delta = 0 # This is the check to know when to stop evaluation\n",
    "            for state in np.ndenumerate(self.values): # Iterate over states - in the form ((row, column), value)\n",
    "                old_value = self.values[state[0]] # Get value of the state\n",
    "                \n",
    "                value = np.sum(self.getDiscountedValuesForSuccessors(state))\n",
    "                self.values[state[0]] = value\n",
    "\n",
    "                delta = max(delta, np.absolute(old_value - value))\n",
    "            \n",
    "            if delta < self.theta:\n",
    "                break\n",
    "\n",
    "    def policyImprovement(self):\n",
    "        while True:\n",
    "            stable = True\n",
    "            for coords, value in np.ndenumerate(self.values):\n",
    "                old_action = np.argmax(self.policies[coords])\n",
    "                self.updatePolicy(coords)\n",
    "\n",
    "                self.policies[coords] = self.policies[coords]\n",
    "                action = np.argmax(self.policies[coords])\n",
    "                if old_action != action:\n",
    "                    stable = False\n",
    "\n",
    "            if not stable:\n",
    "                self.policyEvaluation()\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    '''\n",
    "    Outputs the policy in a readable format\n",
    "    '''\n",
    "    def outputPolicy(self):\n",
    "\n",
    "        mapping = {0: \"Up\", 1: \"Right\", 2: \"Down\", 3: \"Left\"}\n",
    "\n",
    "        output = []\n",
    "\n",
    "        for row in range(len(self.policies)):\n",
    "            row_output = []\n",
    "            for cell in range(len(self.policies[row])):\n",
    "                # row_output.append(mapping[np.argmax(self.policies[row][cell])])\n",
    "                print('{:^6s}'.format(mapping[np.argmax(self.policies[row][cell])]), end=\"\")\n",
    "            print()\n",
    "            # output.append(row_output)\n",
    "        \n",
    "        # print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Agent(10, 10, (6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.policyImprovement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0.2,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0.2,  4.4,  0.2,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  0. ,  0.2,  4.4, 88.9,  4.4,  0.2,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  0.2,  4.4, 88.9,  4.4, 88.9,  4.4,  0.2],\n",
       "       [ 0. ,  0. ,  0. ,  0. ,  0.2,  4.4, 88.9,  4.4,  0.2,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0.2,  4.4,  0.2,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0.2,  0. ,  0. ,  0. ]])"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.values.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right  Down  Down  Down  Down  Down  Down  Down  Down \n",
      " Down Right  Down  Down  Down  Down  Down  Down  Down  Down \n",
      "Right Right Right  Down  Down  Down  Down  Down  Down  Down \n",
      "Right Right Right Right  Down  Down  Down  Down  Down  Down \n",
      "Right Right Right Right  Down  Down  Down  Down  Left  Left \n",
      "Right Right Right Right Right  Down  Down  Down  Left  Left \n",
      "Right Right Right Right Right Right Right  Left  Left  Left \n",
      "Right Right Right Right Right Right   Up    Up   Left  Left \n",
      "Right Right Right Right   Up    Up    Up    Up    Up   Left \n",
      "Right Right Right Right   Up    Up    Up    Up    Up    Up  \n"
     ]
    }
   ],
   "source": [
    "a.outputPolicy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b71e2ea7fd88c01752403482f8b390a2bb97379ffce9aede2d7f28ae0381b030"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
