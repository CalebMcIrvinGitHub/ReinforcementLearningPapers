{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of policy iteration (Sutton and Barto, section 4.3, page 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    '''\n",
    "    Initializes the agent\n",
    "    @param rows - The number of rows in the grid world\n",
    "    @param columns - The number of columns in the grid world\n",
    "    @param terminal_state - The final state the agent is trying to find the best path to\n",
    "    '''\n",
    "    def __init__(self, rows, columns, terminal_state, theta=0.05, gamma=0.05):\n",
    "        # self.grid = np.random.rand(rows, columns) * -1 # Initializes\n",
    "        self.rows = rows\n",
    "        self.columns = columns\n",
    "        self.values = np.zeros((rows, columns)) # Initializes all state values to zero\n",
    "        self.policies = self.initializePolicies()\n",
    "        # self.policies = self.initializePolicies() # Initializes policies for each cell,\n",
    "        #                                           # policies[row][column] is an array where the value\n",
    "        #                                           # at index 0 is the probability that up is the optimal choice,\n",
    "        #                                           # 1 is right, 2 is down, 3 is left (clockwise around Cartesian)\n",
    "        self.terminal_state = terminal_state # Where the end state is located on the grid\n",
    "        self.theta = theta # A value close to zero signifying completion, determines the accuracy of the policy estimation\n",
    "        self.gamma = gamma # A value signifying by how much to discount future rewards \n",
    "\n",
    "    '''\n",
    "    Initializes the policies for each cell in the grid world\n",
    "    '''\n",
    "    def initializePolicies(self):\n",
    "        policies = np.empty((self.rows, self.columns, 4))\n",
    "\n",
    "        # Fill the array with random values that sum to 1\n",
    "        for i in range(self.rows):\n",
    "            for j in range(self.columns):\n",
    "                policies[i, j] = np.random.dirichlet(np.ones(4))\n",
    "                # policies[i, j] = np.zeros(4)\n",
    "                # policies[i, j][np.random.randint(4)] = 1\n",
    "\n",
    "        return policies\n",
    "\n",
    "    def isValidState(self, coords):\n",
    "        return coords[0] >= 0 and coords[0] < self.rows and coords[1] >= 0 and coords[1] < self.columns\n",
    "\n",
    "    '''\n",
    "    Gets the available successor states (necessary because our grid world has walls)\n",
    "    @param coords - coordinates in tuple form (x, y) of our state\n",
    "    @return a list of successors\n",
    "    '''\n",
    "    def getAvailableSuccessorStates(self, coords):\n",
    "        successors = []\n",
    "        \n",
    "        # if coords[1] != 0:\n",
    "        successors.append((coords[0] - 1, coords[1]))\n",
    "\n",
    "        # if coords[0] != self.rows - 1:\n",
    "        successors.append((coords[0], coords[1] + 1))\n",
    "\n",
    "        # if coords[1] != self.columns - 1:\n",
    "        successors.append((coords[0] + 1, coords[1]))\n",
    "\n",
    "        # if coords[0] != 0:\n",
    "        successors.append((coords[0], coords[1] - 1))\n",
    "\n",
    "        return successors\n",
    "\n",
    "    def getDiscountedValuesForSuccessors(self, state):\n",
    "        values = np.zeros(4)\n",
    "        \n",
    "        successors = self.getAvailableSuccessorStates(state[0]) # Get possible next states\n",
    "        \n",
    "        value = 0\n",
    "        for successor in range(len(successors)):\n",
    "            if self.isValidState(successors[successor]):\n",
    "                probability_successor_chosen = self.policies[state[0][0]][state[0][1]][successor]\n",
    "                successor_value = self.getReward(successors[successor]) + self.gamma * self.values[successors[successor][0]][successors[successor][1]]\n",
    "                values[successor] = probability_successor_chosen * successor_value\n",
    "        \n",
    "        # print(state, successors, values)\n",
    "\n",
    "        return values\n",
    "\n",
    "    def updatePolicy(self, coords):\n",
    "        successors = self.getAvailableSuccessorStates(coords)\n",
    "        values = np.ones(4) / 4\n",
    "        for successor in range(len(successors)):\n",
    "            if self.isValidState(successors[successor]):\n",
    "                values[successor] = self.values[successors[successor][0]][successors[successor][1]]\n",
    "            else:\n",
    "                values[successor] = 0\n",
    "                # print(\"Invalid\", coords, successors[successor])\n",
    "        \n",
    "        sum = np.sum(values)\n",
    "        policies = np.ones(4) / 4 if sum == 0 else values / sum\n",
    "\n",
    "        self.policies[coords[0]][coords[1]] = policies\n",
    "\n",
    "\n",
    "    def getReward(self, state):\n",
    "        if state[0] == self.terminal_state[0] and state[1] == self.terminal_state[1]:\n",
    "            # print(state, self.terminal_state)\n",
    "            return 100\n",
    "        return 0\n",
    "        \n",
    "\n",
    "    '''\n",
    "    Performs a policy evaluation step, updates the policy\n",
    "    '''\n",
    "    def policyEvaluation(self):\n",
    "        while True:\n",
    "            delta = 0 # This is the check to know when to stop evaluation\n",
    "            for state in np.ndenumerate(self.values): # Iterate over states - in the form ((row, column), value)\n",
    "                old_value = self.values[state[0]] # Get value of the state\n",
    "                \n",
    "                value = np.sum(self.getDiscountedValuesForSuccessors(state))\n",
    "                self.values[state[0]] = value\n",
    "\n",
    "                delta = max(delta, np.absolute(old_value - value))\n",
    "            \n",
    "            if delta < self.theta:\n",
    "                print()\n",
    "                break\n",
    "\n",
    "            print(self.values)\n",
    "\n",
    "    def policyImprovement(self):\n",
    "        while True:\n",
    "            stable = True\n",
    "            for coords, value in np.ndenumerate(self.values):\n",
    "                old_action = np.argmax(self.policies[coords])\n",
    "                self.updatePolicy(coords)\n",
    "\n",
    "                self.policies[coords] = self.policies[coords]\n",
    "                action = np.argmax(self.policies[coords])\n",
    "                if old_action != action:\n",
    "                    stable = False\n",
    "            \n",
    "            print(self.policies)\n",
    "\n",
    "            if not stable:\n",
    "                # print(self.policies)\n",
    "                self.policyEvaluation()\n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Agent(3, 5, (2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]]\n",
      "\n",
      " [[0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]]\n",
      "\n",
      " [[0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]]]\n",
      "[[ 0.     0.     0.     0.     0.   ]\n",
      " [ 0.     0.     0.     0.    25.   ]\n",
      " [ 0.     0.     0.    25.     0.625]]\n",
      "[[ 0.          0.          0.          0.          0.3125    ]\n",
      " [ 0.          0.          0.          0.625      25.01953125]\n",
      " [ 0.          0.          0.3125     25.01953125  0.62548828]]\n",
      "\n",
      "[[[2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]\n",
      "  [2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]\n",
      "  [0.00000000e+00 5.00000000e-01 5.00000000e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 3.33333333e-01 6.66666667e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 9.99531836e-01 4.68164406e-04]]\n",
      "\n",
      " [[2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]\n",
      "  [0.00000000e+00 7.50000000e-01 2.50000000e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 6.66631990e-01 3.33368010e-01 0.00000000e+00]\n",
      "  [2.34082200e-04 4.99765912e-01 4.99765924e-01 2.34082200e-04]\n",
      "  [2.00037393e-01 0.00000000e+00 3.99887821e-01 4.00074786e-01]]\n",
      "\n",
      " [[0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [4.68091347e-04 9.99375878e-01 0.00000000e+00 1.56030449e-04]\n",
      "  [4.00062297e-01 3.99875339e-01 0.00000000e+00 2.00062364e-01]\n",
      "  [4.99999994e-01 0.00000000e+00 0.00000000e+00 5.00000006e-01]]]\n",
      "[[0.00000000e+00 0.00000000e+00 5.85937500e-04 2.60742187e-02\n",
      "  1.25039255e+00]\n",
      " [0.00000000e+00 4.88281250e-04 2.60744901e-02 1.25039256e+00\n",
      "  4.00388072e+01]\n",
      " [1.95312500e-04 1.56469727e-02 1.25019760e+00 4.00375574e+01\n",
      "  2.00190911e+00]]\n",
      "[[0.00000000e+00 1.34277344e-05 1.30371772e-03 6.25196279e-02\n",
      "  2.00100459e+00]\n",
      " [8.54492188e-06 1.17338054e-03 6.25163784e-02 2.00097335e+00\n",
      "  4.00888498e+01]\n",
      " [7.82348633e-04 6.25098800e-02 2.00063040e+00 4.00875978e+01\n",
      "  2.00441119e+00]]\n",
      "\n",
      "[[[0.00000000e+00 5.58800449e-01 4.41199551e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 4.99991027e-01 4.99965041e-01 4.39318693e-05]\n",
      "  [0.00000000e+00 4.99938213e-01 4.99907047e-01 1.54740559e-04]\n",
      "  [0.00000000e+00 4.99614148e-01 4.99606346e-01 7.79505334e-04]\n",
      "  [0.00000000e+00 0.00000000e+00 9.97510535e-01 2.48946548e-03]]\n",
      "\n",
      " [[4.39347235e-05 4.99997523e-01 4.99958542e-01 0.00000000e+00]\n",
      "  [1.54735316e-04 4.99890106e-01 4.99832988e-01 1.22170896e-04]\n",
      "  [7.78970879e-04 4.99263800e-01 4.99178299e-01 7.78930393e-04]\n",
      "  [1.24475223e-03 4.98763075e-01 4.98747498e-01 1.24467463e-03]\n",
      "  [3.33284552e-01 0.00000000e+00 3.33436101e-01 3.33279347e-01]]\n",
      "\n",
      " [[2.44363708e-04 9.99755636e-01 0.00000000e+00 0.00000000e+00]\n",
      "  [1.55557068e-03 9.96888980e-01 0.00000000e+00 1.55544940e-03]\n",
      "  [2.48320727e-03 9.95033869e-01 0.00000000e+00 2.48292353e-03]\n",
      "  [3.33300105e-01 3.33456868e-01 0.00000000e+00 3.33243026e-01]\n",
      "  [5.00007808e-01 0.00000000e+00 0.00000000e+00 4.99992192e-01]]]\n",
      "[[1.40459069e-06 1.56284083e-04 5.00153064e-03 1.00096647e-01\n",
      "  1.99947120e+00]\n",
      " [1.56273929e-04 5.00047892e-03 1.00009522e-01 1.99944005e+00\n",
      "  3.34436656e+01]\n",
      " [5.00035571e-03 9.98457904e-02 1.99445691e+00 3.34456588e+01\n",
      "  1.67223311e+00]]\n",
      "[[7.81398017e-06 2.50039272e-04 5.00188213e-03 9.98950469e-02\n",
      "  1.66803287e+00]\n",
      " [2.50009898e-04 4.99500298e-03 9.96922716e-02 1.66808263e+00\n",
      "  3.34270826e+01]\n",
      " [4.99107264e-03 9.94133826e-02 1.66400288e+00 3.34290922e+01\n",
      "  1.67140437e+00]]\n",
      "\n",
      "[[[0.         0.50027047 0.49972953 0.        ]\n",
      "  [0.         0.50000725 0.49873982 0.00125293]\n",
      "  [0.         0.49974634 0.49875504 0.00149862]\n",
      "  [0.         0.49924552 0.49926054 0.00149393]\n",
      "  [0.         0.         0.99751307 0.00248693]]\n",
      "\n",
      " [[0.00125538 0.49971421 0.49903042 0.        ]\n",
      "  [0.00149994 0.49919312 0.49780862 0.00149832]\n",
      "  [0.00149351 0.49911899 0.49789778 0.00148972]\n",
      "  [0.00124343 0.49874281 0.49877279 0.00124097]\n",
      "  [0.33305042 0.         0.33388915 0.33306044]]\n",
      "\n",
      " [[0.00300079 0.99699921 0.         0.        ]\n",
      "  [0.00297424 0.99405558 0.         0.00297017]\n",
      "  [0.00247574 0.99505539 0.         0.00246887]\n",
      "  [0.33332873 0.33415811 0.         0.33251316]\n",
      "  [0.49998497 0.         0.         0.50001503]]]\n",
      "[[1.24888070e-05 2.48818537e-04 4.15655500e-03 8.32372144e-02\n",
      "  1.66720587e+00]\n",
      " [2.48331870e-04 4.14046485e-03 8.30130687e-02 1.66726020e+00\n",
      "  3.34723460e+01]\n",
      " [4.13469669e-03 8.26656282e-02 1.66320835e+00 3.34991755e+01\n",
      "  1.67428806e+00]]\n",
      "\n",
      "[[[0.         0.50066059 0.49933941 0.        ]\n",
      "  [0.         0.50048413 0.49801699 0.00149887]\n",
      "  [0.         0.50004864 0.49870681 0.00124455]\n",
      "  [0.         0.49927875 0.49948011 0.00124113]\n",
      "  [0.         0.         0.99751943 0.00248057]]\n",
      "\n",
      " [[0.00150416 0.49977331 0.49872253 0.        ]\n",
      "  [0.00124728 0.49979823 0.4977105  0.00124399]\n",
      "  [0.00124063 0.49927684 0.49824802 0.00123451]\n",
      "  [0.00123979 0.49856191 0.49896183 0.00123647]\n",
      "  [0.33296748 0.         0.33393076 0.33310177]]\n",
      "\n",
      " [[0.00249319 0.99750681 0.         0.        ]\n",
      "  [0.0024655  0.99507417 0.         0.00246032]\n",
      "  [0.00246589 0.99507853 0.         0.00245559]\n",
      "  [0.33328578 0.33411522 0.         0.332599  ]\n",
      "  [0.49979954 0.         0.         0.50020046]]]\n"
     ]
    }
   ],
   "source": [
    "a.policyImprovement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.  ,  0.  ,  0.08,  1.67],\n",
       "       [ 0.  ,  0.  ,  0.08,  1.67, 33.47],\n",
       "       [ 0.  ,  0.08,  1.67, 33.5 ,  1.67]])"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.values.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.  , 0.5 , 0.5 , 0.  ],\n",
       "        [0.  , 0.5 , 0.5 , 0.  ],\n",
       "        [0.  , 0.5 , 0.5 , 0.  ],\n",
       "        [0.  , 0.5 , 0.5 , 0.  ],\n",
       "        [0.  , 0.  , 1.  , 0.  ]],\n",
       "\n",
       "       [[0.  , 0.5 , 0.5 , 0.  ],\n",
       "        [0.  , 0.5 , 0.5 , 0.  ],\n",
       "        [0.  , 0.5 , 0.5 , 0.  ],\n",
       "        [0.  , 0.5 , 0.5 , 0.  ],\n",
       "        [0.33, 0.  , 0.33, 0.33]],\n",
       "\n",
       "       [[0.  , 1.  , 0.  , 0.  ],\n",
       "        [0.  , 1.  , 0.  , 0.  ],\n",
       "        [0.  , 1.  , 0.  , 0.  ],\n",
       "        [0.33, 0.33, 0.  , 0.33],\n",
       "        [0.5 , 0.  , 0.  , 0.5 ]]])"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.policies.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b71e2ea7fd88c01752403482f8b390a2bb97379ffce9aede2d7f28ae0381b030"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
